import logging
import os
from datetime import datetime
from pathlib import Path
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List
from . import models, schemas
from .database import get_db, engine, SessionLocal
from .initial_data import init_db
from sqlalchemy.sql import func

# Configuration simple du logging
def setup_simple_logging():
    """Configuration basique du logging"""
    # Cr√©er le dossier logs
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    # Nom du fichier de log avec date
    log_file = log_dir / f"quiz_app_{datetime.now().strftime('%Y%m%d')}.log"
    
    # Configuration du logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()  # Console
        ]
    )
    
    # R√©duire les logs des librairies tierces
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)

# Initialiser le logging
setup_simple_logging()
logger = logging.getLogger("quiz_app")

models.Base.metadata.create_all(bind=engine)

app = FastAPI(title="Spark Quiz API")

# Ajout du middleware CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Autorise toutes les origines (en dev)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
def on_startup():
    """Initialisation au d√©marrage avec logging"""
    logger.info("üöÄ D√©marrage de l'application Spark Quiz API")
    
    try:
        db = SessionLocal()
        question_count = db.query(models.SparkQuestion).count()
        
        if question_count == 0:
            logger.info("Initialisation de la base de donn√©es avec les questions par d√©faut")
            init_db(db)
            new_count = db.query(models.SparkQuestion).count()
            logger.info(f"‚úÖ {new_count} questions ajout√©es √† la base de donn√©es")
        else:
            logger.info(f"‚úÖ Base de donn√©es d√©j√† initialis√©e avec {question_count} questions")
        
        db.close()
        logger.info("‚úÖ Application d√©marr√©e avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'initialisation: {e}", exc_info=True)
        raise

@app.get("/questions/", response_model=List[schemas.SparkQuestion])
def get_questions(
    technology: str = None,
    category: str = None,
    difficulty: int = None,
    db: Session = Depends(get_db)
):
    """R√©cup√®re les questions avec logging"""
    logger.info(f"R√©cup√©ration des questions - tech: {technology}, cat: {category}, diff: {difficulty}")
    
    try:
        query = db.query(models.SparkQuestion)
        if technology:
            query = query.filter(models.SparkQuestion.technology == technology)
        if category:
            query = query.filter(models.SparkQuestion.category == category)
        if difficulty:
            query = query.filter(models.SparkQuestion.difficulty == difficulty)
        
        questions = query.all()
        logger.info(f"‚úÖ {len(questions)} questions r√©cup√©r√©es")
        return questions
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des questions: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur serveur")

@app.get("/questions/{question_id}", response_model=schemas.SparkQuestion)
def get_question(question_id: int, db: Session = Depends(get_db)):
    """R√©cup√®re une question sp√©cifique avec logging"""
    logger.info(f"R√©cup√©ration de la question {question_id}")
    
    try:
        question = db.query(models.SparkQuestion).filter(models.SparkQuestion.id == question_id).first()
        if question is None:
            logger.warning(f"‚ùå Question {question_id} non trouv√©e")
            raise HTTPException(status_code=404, detail="Question not found")
        
        logger.info(f"‚úÖ Question {question_id} r√©cup√©r√©e ({question.technology})")
        return question
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration de la question {question_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur serveur")

@app.post("/questions/", response_model=schemas.SparkQuestion)
def create_question(question: schemas.SparkQuestionCreate, db: Session = Depends(get_db)):
    """Cr√©e une nouvelle question avec logging"""
    logger.info(f"Cr√©ation d'une nouvelle question - tech: {question.technology}")
    
    try:
        # Correction pour compatibilit√© Pydantic v2
        question_data = question.model_dump() if hasattr(question, 'model_dump') else question.dict()
        db_question = models.SparkQuestion(**question_data)
        db.add(db_question)
        db.commit()
        db.refresh(db_question)
        
        logger.info(f"‚úÖ Question cr√©√©e avec l'ID {db_question.id}")
        return db_question
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la cr√©ation de la question: {e}", exc_info=True)
        db.rollback()
        raise HTTPException(status_code=500, detail="Erreur lors de la cr√©ation")

# Route pour obtenir une question al√©atoire
@app.get("/questions/random/", response_model=schemas.SparkQuestion)
def get_random_question(
    technology: str = None,
    category: str = None,
    difficulty: int = None,
    db: Session = Depends(get_db)
):
    """R√©cup√®re une question al√©atoire avec logging"""
    logger.info(f"R√©cup√©ration question al√©atoire - tech: {technology}, cat: {category}, diff: {difficulty}")
    
    try:
        query = db.query(models.SparkQuestion)
        if technology:
            query = query.filter(models.SparkQuestion.technology == technology)
        if category:
            query = query.filter(models.SparkQuestion.category == category)
        if difficulty:
            query = query.filter(models.SparkQuestion.difficulty == difficulty)
        
        question = query.order_by(func.random()).first()
        
        if question is None:
            logger.warning("‚ùå Aucune question al√©atoire trouv√©e avec ces crit√®res")
            raise HTTPException(status_code=404, detail="Aucune question trouv√©e")
        
        logger.info(f"‚úÖ Question al√©atoire r√©cup√©r√©e: ID {question.id} ({question.technology})")
        return question
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration d'une question al√©atoire: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur serveur")

# Routes suppl√©mentaires avec logging
@app.get("/")
def read_root():
    """Page d'accueil de l'API"""
    logger.info("Acc√®s √† la page d'accueil de l'API")
    return {
        "message": "Spark Quiz API", 
        "version": "1.0.0",
        "docs": "/docs",
        "status": "running"
    }

@app.get("/health")
def health_check():
    """V√©rification de l'√©tat de l'application"""
    logger.debug("Health check demand√©")
    return {"status": "healthy"}

@app.get("/stats")
def get_stats(db: Session = Depends(get_db)):
    """Statistiques de l'application"""
    logger.info("R√©cup√©ration des statistiques")
    
    try:
        total_questions = db.query(models.SparkQuestion).count()
        technologies = db.query(models.SparkQuestion.technology).distinct().all()
        tech_count = {tech[0]: db.query(models.SparkQuestion).filter(models.SparkQuestion.technology == tech[0]).count() 
                     for tech in technologies}
        
        stats = {
            "total_questions": total_questions,
            "technologies": list(tech_count.keys()),
            "questions_by_technology": tech_count
        }
        
        logger.info(f"‚úÖ Statistiques calcul√©es: {total_questions} questions total")
        return stats
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du calcul des statistiques: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur serveur")

# Routes utiles pour le d√©veloppement et la production
@app.get("/technologies")
def get_technologies(db: Session = Depends(get_db)):
    """R√©cup√®re la liste des technologies disponibles"""
    logger.info("R√©cup√©ration de la liste des technologies")
    
    try:
        technologies = db.query(models.SparkQuestion.technology).distinct().all()
        tech_list = [tech[0] for tech in technologies]
        
        logger.info(f"‚úÖ {len(tech_list)} technologies trouv√©es: {tech_list}")
        return {"technologies": tech_list}
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des technologies: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur serveur")

@app.get("/categories")
def get_categories(
    technology: str = None,
    db: Session = Depends(get_db)
):
    """R√©cup√®re la liste des cat√©gories disponibles"""
    logger.info(f"R√©cup√©ration des cat√©gories pour la technologie: {technology}")
    
    try:
        query = db.query(models.SparkQuestion.category).distinct()
        if technology:
            query = query.filter(models.SparkQuestion.technology == technology)
        
        categories = query.all()
        cat_list = [cat[0] for cat in categories]
        
        logger.info(f"‚úÖ {len(cat_list)} cat√©gories trouv√©es")
        return {"categories": cat_list}
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des cat√©gories: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Erreur serveur")